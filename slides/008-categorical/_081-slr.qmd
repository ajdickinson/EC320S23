---
name: slr
---

---

## Categorical Variables

[Goal]{.note} Make quantitative statements about [qualitative information]{.purple}.

- *e.g.,* race, gender, being employed, living in Oregon, *etc.*

. . .

[Approach.]{.note} Construct [binary variables]{.hp}.

- _a.k.a._ [dummy variables]{.purple} or [indicator variables]{.purple}.
- Value equals 1 if observation is in the category or 0 if otherwise.

. . .

[Regression implications.]{.note}

1. Change the interpretation of the intercept.

2. Change the interpretations of the slope parameters.


---

## Continuous Variables

Consider the relationship

$$
\text{Pay}_i = \beta_0 + \beta_1 \text{School}_i + u_i
$$

_where_

- $\text{Pay}_i$ is a continuous variable measuring an individual's pay
- $\text{School}_i$ is a continuous variable that measures years of education

. . .

[Interpretation]{.note}

- $\beta_0$: $y$-intercept, _i.e._, $\text{Pay}$ when $\text{School} = 0$
- $\beta_1$: expected increase in $\text{Pay}$ for a one-unit increase in $\text{School}$


---

Consider the relationship

$$
\text{Pay}_i = \beta_0 + \beta_1 \text{School}_i + u_i
$$

[Derive the slope's interpretation.]{.note}

$\mathop{\mathbb{E}}\left[ \text{Pay} | \text{School} = \ell + 1 \right] - \mathop{\mathbb{E}}\left[ \text{Pay} | \text{School} = \ell \right]$

. . .

<br> $\quad = \mathop{\mathbb{E}}\left[ \beta_0 + \beta_1 (\ell + 1) + u \right] - \mathop{\mathbb{E}}\left[ \beta_0 + \beta_1 \ell + u \right]$

. . .

<br> $\quad = \left[ \beta_0 + \beta_1 (\ell + 1) \right] - \left[ \beta_0 + \beta_1 \ell \right]$

. . .

<br> $\quad = \beta_0 - \beta_0 + \beta_1 \ell - \beta_1 \ell + \beta_1$ [$\: = \beta_1$.]{.fragment} 

[Expected increase in pay for an additional year of schooling]{.fragment}

---

## Continuous Variables

Consider the relationship

$$
\text{Pay}_i = \beta_0 + \beta_1 \text{School}_i + u_i
$$

[Alternative derivation:]{.note}

Differentiate the model with respect to schooling:

$$
\dfrac{\partial \text{Pay}}{\partial \text{School}} = \beta_1
$$

[Expected increase in pay for an additional year of schooling]{.fragment}


---

If we have multiple explanatory variables, _e.g._,

$$
\text{Pay}_i = \beta_0 + \beta_1 \text{School}_i + \beta_2 \text{Ability}_i + u_i
$$

then the interpretation changes slightly.

. . .

$\mathop{\mathbb{E}}\left[ \text{Pay} | \text{School} = \ell + 1 \land \text{Ability} = \alpha \right] - \mathop{\mathbb{E}}\left[ \text{Pay} | \text{School} = \ell \land \text{Ability} = \alpha \right]$

. . .

<br> $\quad = \mathop{\mathbb{E}}\left[ \beta_0 + \beta_1 (\ell + 1) + \beta_2 \alpha + u \right] - \mathop{\mathbb{E}}\left[ \beta_0 + \beta_1 \ell + \beta_2 \alpha + u \right]$

. . .

<br> $\quad = \left[ \beta_0 + \beta_1 (\ell + 1) + \beta_2 \alpha \right] - \left[ \beta_0 + \beta_1 \ell + \beta_2 \alpha \right]$

. . .

<br> $\quad = \beta_0 - \beta_0 + \beta_1 \ell - \beta_1 \ell + \beta_1 + \beta_2 \alpha - \beta_2 \alpha$ [$\: = \beta_1$]{.fragment}

. . .

The slope gives the expected increase in pay for an additional year of schooling, **holding ability constant**.


---

## Continuous Variables

If we have multiple explanatory variables, _e.g._,

$$
\text{Pay}_i = \beta_0 + \beta_1 \text{School}_i + \beta_2 \text{Ability}_i + u_i
$$

then the interpretation changes slightly.

. . .

[Alternative derivation]{.note}

Differentiate the model with respect to schooling:

$$
\dfrac{\partial\text{Pay}}{\partial\text{School}} = \beta_1
$$

The slope gives the expected increase in pay for an additional year of schooling, [holding ability constant]{.hi}.


---

## Categorical Variables

Consider the relationship

$$
\text{Pay}_i = \beta_0 + \beta_1 \text{Female}_i + u_i
$$

where $\text{Pay}_i$ is a continuous variable measuring an individual's pay and $\text{Female}_i$ is a binary variable equal to $1$ when $i$ is female.

. . .

[Interpretation of]{.note} $\beta_0$

$\beta_0$ is the expected $\text{Pay}$ for males (_i.e._, when $\text{Female} = 0$):

. . .

$$
\mathop{\mathbb{E}}\left[ \text{Pay} | \text{Male} \right] = \mathop{\mathbb{E}}\left[ \beta_0 + \beta_1\times 0 + u_i \right] = \mathop{\mathbb{E}}\left[ \beta_0 + 0 + u_i \right] = \beta_0
$$


---

## Categorical Variables

Consider the relationship

$$
\text{Pay}_i = \beta_0 + \beta_1 \text{Female}_i + u_i
$$

where $\text{Pay}_i$ is a continuous variable measuring an individual's pay and $\text{Female}_i$ is a binary variable equal to $1$ when $i$ is female.

. . .

[Interpretation of]{.note} $\beta_1$

$\beta_1$ is the expected difference in $\text{Pay}$ between females and males:

. . .

$\mathop{\mathbb{E}}\left[ \text{Pay} | \text{Female} \right] - \mathop{\mathbb{E}}\left[ \text{Pay} | \text{Male} \right]$
. . .
$\quad = \mathop{\mathbb{E}}\left[ \beta_0 + \beta_1\times 1 + u_i \right] - \mathop{\mathbb{E}}\left[ \beta_0 + \beta_1\times 0 + u_i \right]$
. . .
$\quad = \mathop{\mathbb{E}}\left[ \beta_0 + \beta_1 + u_i \right] - \mathop{\mathbb{E}}\left[ \beta_0 + 0 + u_i \right]$
. . .
$\quad = \beta_0 + \beta_1 - \beta_0$
. . .
$\quad = \beta_1$


---

## Categorical Variables

Consider the relationship

$$
\text{Pay}_i = \beta_0 + \beta_1 \text{Female}_i + u_i
$$

where $\text{Pay}_i$ is a continuous variable measuring an individual's pay and $\text{Female}_i$ is a binary variable equal to $1$ when $i$ is female.

[Interpretation]{.note}

$\beta_0 + \beta_1$: is the expected $\text{Pay}$ for females:

$\mathop{\mathbb{E}}\left[ \text{Pay} | \text{Female} \right]$

. . .

$\quad = \mathop{\mathbb{E}}\left[ \beta_0 + \beta_1\times 1 + u_i \right]$

. . .

$\quad = \mathop{\mathbb{E}}\left[ \beta_0 + \beta_1 + u_i \right]$

. . .

$\quad = \beta_0 + \beta_1$


---

## Categorical Variables

Consider the relationship

$$
\text{Pay}_i = \beta_0 + \beta_1 \text{Female}_i + u_i
$$

[Interpretation]{.note}

- $\beta_0$: expected $\text{Pay}$ for males (_i.e._, when $\text{Female} = 0$)
- $\beta_1$: expected difference in $\text{Pay}$ between females and males
- $\beta_0 + \beta_1$: expected $\text{Pay}$ for females
- Males are the [reference group]{.hi}

---

## Categorical Variables {data-visibility="uncounted"}

Consider the relationship

$$
\text{Pay}_i = \beta_0 + \beta_1 \text{Female}_i + u_i
$$


[Note.]{.note} If there are no other variables to condition on, then $\hat{\beta}_1$ equals the difference in group means, _e.g._, $\bar{X}_\text{Female} - \bar{X}_\text{Male}$.

<br>

. . .

[Note~2~.]{.note} The *holding all other variables constant* interpretation also applies for categorical variables in multiple regression settings.

---

## Categorical Variables

$Y_i = \beta_0 + \beta_1 X_i + u_i$ for binary variable $X_i = \{\color{#434C5E}{0}, \, {\color{#B48EAD}{1}}\}$

```{r}
#| include: false

# Set seed
set.seed(1235)
# Sample size
n <- 5e3
# Generate data
cat_df <- tibble(
  x = sample(x = c(0, 1), size = n, replace = T),
  y = 3 + 7 * x + rnorm(n, sd = 2)
)
# Regression
cat_reg <- lm(y ~ x, data = cat_df)
```

```{r}
#| echo: false
#| fig.height: 5.75
#| fig-align: center

set.seed(12345)
ggplot(data = cat_df, aes(x = x, y = y, color = as.factor(x))) +
geom_point(width = 0.3, size = 1.5, alpha = 0.5) +
scale_color_manual(values = c(hi, hp)) +
scale_x_continuous(breaks = c(0,1)) +
mytheme_s +
theme(
  legend.position = "none",
  axis.line.y = element_blank(),
  axis.text.y = element_blank()
)
```

---

## Categorical Variables {data-visibility="uncounted"}

$Y_i = \beta_0 + \beta_1 X_i + u_i$ for binary variable $X_i = \{\color{#434C5E}{0}, \, {\color{#B48EAD}{1}}\}$

```{r}
#| echo: false
#| fig.height: 5.75
#| fig-align: center

set.seed(12345)
ggplot(data = cat_df, aes(x = x, y = y, color = as.factor(x))) +
geom_jitter(width = 0.3, size = 1.5, alpha = 0.5) +
scale_color_manual(values = c(hi, hp)) +
scale_x_continuous(breaks = c(0,1)) +
mytheme_s +
theme(
  legend.position = "none",
  axis.line.y = element_blank(),
  axis.text.y = element_blank()
)
```

---

## Categorical Variables

$Y_i = \beta_0 + \beta_1 X_i + u_i$ for binary variable $X_i = \{\color{#434C5E}{0}, \, {\color{#B48EAD}{1}}\}$

```{r}
#| echo: false
#| fig.height: 5.75
#| fig-align: center

set.seed(12345)
ggplot(data = cat_df, aes(x = x, y = y, color = as.factor(x))) +
geom_jitter(width = 0.3, size = 1.5, alpha = 0.5) +
scale_color_manual(values = c(hi, hp)) +
scale_x_continuous(breaks = c(0,1)) +
geom_hline(yintercept = cat_reg$coefficients[1], size = 1, color = hi) +
geom_hline(yintercept = cat_reg$coefficients[1] + cat_reg$coefficients[2], size = 1, color = hp) +
annotate(
  geom = "text",
  x = 0.5,
  y = -1.5 + cat_reg$coefficients[1],
  label = latex2exp::TeX("$\\hat{\\beta}_0 = \\bar{Group_0}$"),
  size = 7
) +
annotate(
  geom = "text",
  x = 0.5,
  y = 1.5 + cat_reg$coefficients[1] + cat_reg$coefficients[2],
  label = latex2exp::TeX("$\\hat{\\beta}_0 + \\hat{\\beta}_1 = \\bar{Group_1}$"),
  size = 7,
  color = hp
) +
mytheme_s +
theme(
  legend.position = "none",
  axis.line.y = element_blank(),
  axis.text.y = element_blank()
)
```

---

## Multiple Regression

```{R, gen data, cache = T, include = F}
n <- 1e2
set.seed(1234)
gen_df <- tibble(
  x1 = runif(n = n, min = -3, max = 3),
  x2 = sample(x = c(F, T), size = n, replace = T),
  u  = rnorm(n = n, mean = 0, sd = 1),
  y  = -0.5 + x1 + x2 * 4 + u
)
mean_a <- filter(gen_df, x2 == F)$y %>% mean()
mean_b <- filter(gen_df, x2 == T)$y %>% mean()
gen_df %<>% mutate(y_dm = y - mean_a * (x2 == F) - mean_b * (x2 == T))
```

$Y_i = \beta_0 + \beta_1 X_{1i} + \beta_2 X_{2i} + u_i \quad$ $X_1$ is continuous $\quad X_2$ is categorical

```{r}
#| echo: false
#| fig.height: 5.75
#| fig-align: center

ggplot(data = gen_df, aes(y = y, x = x1, color = x2, shape = x2)) +
geom_hline(yintercept = 0) +
geom_vline(xintercept = 0) +
annotate("text", x = -0.075, y = 7.75, label = latex2exp::TeX("$Y$"), size = 8) +
annotate("text", x = 2.95, y = 0.3, label = latex2exp::TeX("$X_1$"), size = 8) +
geom_point(size = 3) +
ylim(c(-4.5, 8)) +
theme_void() +
scale_color_manual(
  expression(X[2]),
  values = c(hi, hp),
  labels = c("A", "B")
) +
scale_shape_manual(
  expression(X[2]),
  values = c(1, 19),
  labels = c("A", "B")
) +
theme(
  text = element_text(size = 20),
  legend.position = "none"
)
```

---

## Multiple Regression

The intercept and categorical variable $X_2$ control for the groups' means.

```{r}
#| echo: false
#| fig.height: 5.75
#| fig-align: center

ggplot(data = gen_df, aes(y = y, x = x1, color = x2, shape = x2)) +
geom_hline(yintercept = mean_a, color = hi, alpha = 0.5) +
geom_hline(yintercept = mean_b, color = hp, alpha = 0.5) +
geom_hline(yintercept = 0) +
geom_vline(xintercept = 0) +
annotate("text", x = -0.075, y = 7.75, label = latex2exp::TeX("$Y$"), size = 8) +
annotate("text", x = 2.95, y = 0.3, label = latex2exp::TeX("$X_1$"), size = 8) +
geom_point(size = 3) +
ylim(c(-4.5, 8)) +
theme_void() +
scale_color_manual(
  expression(X[2]),
  values = c(hi, hp),
  labels = c("A", "B")
) +
scale_shape_manual(
  expression(X[2]),
  values = c(1, 19),
  labels = c("A", "B")
) +
theme(
  text = element_text(size = 20),
  legend.position = "none"
)
```

---

## Multiple Regression

With groups' means removed:

```{r}
#| echo: false
#| fig.height: 5.75
#| fig-align: center

ggplot(data = gen_df %>% mutate(y = y - 4 * x2), aes(y = y_dm, x = x1)) +
geom_hline(yintercept = 0) +
geom_vline(xintercept = 0) +
annotate("text", x = -0.075, y = 7.75, label = latex2exp::TeX("$Y$"), size = 8) +
annotate("text", x = 2.95, y = 0.3, label = latex2exp::TeX("$X_1$"), size = 8) +
geom_point(size = 3, aes(color = x2, shape = x2)) +
ylim(c(-4.5, 8)) +
theme_void() +
scale_color_manual(
  expression(X[2]),
  values = c(hi, hp),
  labels = c("A", "B")
) +
scale_shape_manual(
  expression(X[2]),
  values = c(1, 19),
  labels = c("A", "B")
) +
theme(
  text = element_text(size = 20),
  legend.position = "none"
)
```

---

## Multiple Regression

$\hat{\beta}_1$ estimates the relationship between $Y$ and $X_1$ after controlling for $X_2$.

```{r}
#| echo: false
#| fig.height: 5.75
#| fig-align: center

ggplot(data = gen_df %>% mutate(y = y - 4 * x2), aes(y = y_dm, x = x1)) +
geom_smooth(method = lm, se = F, color = hii) +
geom_hline(yintercept = 0) +
geom_vline(xintercept = 0) +
annotate("text", x = -0.075, y = 7.75, label = latex2exp::TeX("$Y$"), size = 8) +
annotate("text", x = 2.95, y = 0.3, label = latex2exp::TeX("$X_1$"), size = 8) +
geom_point(size = 3, aes(color = x2, shape = x2)) +
ylim(c(-4.5, 8)) +
theme_void() +
scale_color_manual(
  expression(X[2]),
  values = c(hi, hp),
  labels = c("A", "B")
) +
scale_shape_manual(
  expression(X[2]),
  values = c(1, 19),
  labels = c("A", "B")
) +
theme(
  text = element_text(size = 20),
  legend.position = "none"
)
```

---

## Multiple Regression

Another way to think about it:

```{r}
#| echo: false
#| fig.height: 5.75
#| fig-align: center

ggplot(data = gen_df, aes(y = y, x = x1, color = x2, shape = x2)) +
geom_smooth(method = lm, se = F) +
geom_hline(yintercept = 0) +
geom_vline(xintercept = 0) +
annotate("text", x = -0.075, y = 7.75, label = latex2exp::TeX("$Y$"), size = 8) +
annotate("text", x = 2.95, y = 0.3, label = latex2exp::TeX("$X_1$"), size = 8) +
geom_point(size = 3) +
ylim(c(-4.5, 8)) +
theme_void() +
scale_color_manual(
  expression(X[2]),
  values = c(hi, hp),
  labels = c("A", "B")
) +
scale_shape_manual(
  expression(X[2]),
  values = c(1, 19),
  labels = c("A", "B")
) +
theme(
  text = element_text(size = 20),
  legend.position = "none"
)
```
