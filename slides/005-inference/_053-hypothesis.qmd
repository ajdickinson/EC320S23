---
name: hypothesis
---

---

## Hypothesis Tests

[Null hypothesis:]{.hi} $\beta_2 = 0$

[Alternative hypothesis]{.hi} $\beta_2 \neq 0$

. . .

There are four possible outcomes of our test:

1. We __fail to reject__ the null hypothesis and the null is true.

2. We __reject__ the null hypothesis and the null is false.

3. We __reject__ the null hypothesis, but the null is actually true (**Type I error**).

4. We __fail to reject__ the null hypothesis, but the null is actually false (**Type II error**).

---

## Hypothesis Tests

**Goal:** Make a statement about $\beta_2$ using information on $\hat{\beta}_2$.

. . .

$\hat{\beta}_2$ is random: it could be anything, even if $\beta_2 = 0$ is true.

- But if $\beta_2 = 0$ is true, then $\hat{\beta}_2$ is unlikely to take values far from zero.
- As the standard error shrinks, we are even less likely to observe "extreme" values of $\hat{\beta}_2$ (assuming $\beta_2 = 0$).

. . .

Our test should take [extreme values]{.hp} of $\hat{\beta}_2$ as [evidence against the null hypothesis]{.hp}, but it should also weight them by what we know about the variance of $\hat{\beta}_2$.

---

## Hypothesis Tests

:::: {.columns}

::: {.column width="50%"}
[Null hypothesis:]{.hi} $\beta_2 = 0$
:::

::: {.column width="50%"}
[Alternative hypothesis:]{.hi} $\beta_2 \neq 0$
:::

::::

<br>
<br>

To conduct the test, we calculate a $t$-statistic:

$$
t = \frac{\hat{\beta}_2 - \beta_2^0}{\mathop{\hat{\text{SE}}} \left( \hat{\beta}_2 \right)}
$$

- Distributed according to a $t$-distribution with $n-2$ _degrees of freedom_.
- $\beta_2^0$ is the value of $\beta_2$ in our null hypothesis (*e.g.,* $\beta_2^0 = 0$).


---

## Hypothesis Tests

Next, we use the $\color{#434C5E}{t}$[-statistic]{.hi} to calculate a $\color{#B48EAD}{p}$[-value]{.hp}.

```{r}
#| echo: false
#| fig.height: 3.75

df <- tibble(
    x = seq(-4,4, by = 0.01),
    y = dt(seq(-4,4, by = 0.01), 100)
)
t <- qt(c(.025,.8), 100)
tail_right <- rbind(c(t[2],0), subset(df, x > t[2]), c(3,0))
ggplot() +
  scale_x_continuous(limits = c(-4, 4), expand=c(0,0)) +
  scale_y_continuous(limits = c(0, 0.5), expand=c(0,0), breaks = c(0, 0.5), labels = c(0, 0.5)) +
  geom_polygon(data = df, aes(x, y), fill = "grey85") +
  geom_polygon(data = tail_right, aes(x=x, y=y), fill = hii) +
  geom_vline(xintercept = qt(0.8, 100), size = 1, linetype = "solid", color = hi) +
  mytheme_s +
  xlab("") + 
  ylab("") + theme(axis.text.y = element_blank(), axis.line.y = element_blank())
```

Describes the probability of seeing a $t$-statistic as extreme as the one we observe _if the null hypothesis is actually true_.

. . .

But...we still need some benchmark to compare our $p$-value against.

---

## Hypothesis Tests

We worry mostly about false positives, so we conduct hypothesis tests based on the probability of making a Type I error.

**How?** We select a [significance level]{.note} $\color{#434C5E}{\alpha}$ that specifies our tolerance for false positives. This is the probability of Type I error we choose to live with.

```{r}
#| echo: false
#| fig.height: 3.75

df <- tibble(
    x = seq(-4,4, by = 0.01),
    y = dt(seq(-4,4, by = 0.01), 100)
)
crit <- qt(c(.025,.975), 100)
tail_left <- rbind(c(crit[1],0), subset(df, x < crit[1]))
tail_right <- rbind(c(crit[2],0), subset(df, x > crit[2]), c(3,0))
ggplot() +
  scale_x_continuous(limits = c(-4, 4), expand=c(0,0)) +
  scale_y_continuous(limits = c(0, 0.5), expand=c(0,0), breaks = c(0, 0.5), labels = c(0, 0.5)) +
  geom_polygon(data = df, aes(x, y), fill = "grey85") +
  geom_polygon(data = tail_left, aes(x=x, y=y), fill = hp) +
  geom_polygon(data = tail_right, aes(x=x, y=y), fill = hp) +
  geom_polygon(data = df %>% filter(x <= qt(1 - 0.975, 100) & x >= qt(0.975, 100)), aes(x, y), fill = hp) +
  #geom_vline(xintercept = qt(0.975, 100), size = 0.35, linetype = "dashed", color = hi) +
  #geom_vline(xintercept = qt(1 - 0.975, 100), size = 0.35, linetype = "dashed", color = hi) +
  mytheme_s +
  xlab("") + 
  ylab("") + theme(axis.text.y = element_blank(), axis.line.y = element_blank())
```

---

## Hypothesis Tests

We then compare $\alpha$ to the $p$-value of our test.

- If the $p$-value is less than $\alpha$, then we __reject the null hypothesis__ at the $\alpha\cdot100$ percent level.

- If the $p$-value is greater than $\alpha$, then we __fail to reject the null hypothesis__.

- **Note:** _Fail to reject_ $\neq$ _accept_.

---

## Hypothesis Tests

**Example:** Are campus police associated with campus crime?

```{R echo = T, highlight.output = 5}
lm(crime ~ police, data = campus) %>% tidy()
```

[Null hypothesis:]{.hi} $\beta_\text{Police} = 0$ *v.s.* [Alternative hypothesis:]{.hi} $\beta_\text{Police} \neq 0$

. . .

Significance level: $\alpha = 0.05$ (*i.e.,* 5 percent test)

. . .

Test Condition: Reject H.sub[0] if $p < \alpha$

. . .

$p = 0.18$. **Do we reject the null hypothesis?**

---

## Hypothesis Tests

$p$-values are difficult to calculate by hand.

__Alternative:__ Compare $\color{#434C5E}{t}$[-statistic]{.hi} to [critical values]{.note} from the ${\color{#434C5E} t}$-distribution.

```{r}
#| echo: false
#| fig.height: 3.75

df <- tibble(
    x = seq(-4,4, by = 0.01),
    y = dt(seq(-4,4, by = 0.01), 100)
)
crit <- qt(c(.025,.975), 100)
tail_left <- rbind(c(crit[1],0), subset(df, x < crit[1]))
tail_right <- rbind(c(crit[2],0), subset(df, x > crit[2]), c(3,0))
ggplot() +
  scale_x_continuous(limits = c(-4, 4), expand=c(0,0)) +
  scale_y_continuous(limits = c(0, 0.5), expand=c(0,0), breaks = c(0, 0.5), labels = c(0, 0.5)) +
  geom_polygon(data = df, aes(x, y), fill = "grey85") +
  geom_polygon(data = tail_left, aes(x=x, y=y), fill = hii) +
  geom_polygon(data = tail_right, aes(x=x, y=y), fill = hii) +
  geom_polygon(data = df %>% filter(x <= qt(1 - 0.975, 100) & x >= qt(0.975, 100)), aes(x, y), fill = hp) +
  geom_vline(xintercept = qt(0.975, 100), size = 0.35, linetype = "dashed", color = hi) +
  geom_vline(xintercept = qt(1 - 0.975, 100), size = 0.35, linetype = "dashed", color = hi) +
  geom_vline(xintercept = 1, linetype = "solid", color = hp) +
  mytheme_s +
  xlab("") + 
  ylab("") + theme(axis.text.y = element_blank(), axis.line.y = element_blank())
```

---

## Hypothesis Tests

**Notation:** $t_{1-\alpha/2, n-2}$ or $t_\text{crit}$.

- Find in a $t$ table using the significance level $\alpha$ and $n-2$ degrees of freedom.

Compare the the critical value to your $t$-statistic:

- If $|t| > |t_{1-\alpha/2, n-2}|$, then __reject the null__.
- If $|t| < |t_{1-\alpha/2, n-2}|$, then __fail to reject the null__.
