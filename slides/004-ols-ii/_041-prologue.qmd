---
name: prologue
---

---

## Last Time

We considered a simple linear regression of $Y_i$ on $X_i$:

$$
 Y_i = \beta_1 + \beta_2X_i + u_i.
$$

. . .

- $\beta_1$ and $\beta_2$ are [population parameters]{.note} that describe the *"true"* relationship between $X_i$ and $Y_i$.
- [Problem:]{.hi} We don't know the population parameters. The best we can do is to estimate them.

---

## Last Time

We derived the [OLS]{.hi} estimator by minimizing $\sum_{i=1}^n \hat{u}_i^2$.

:::: {.columns}
::: {.column width="40%"}
[Intercept:]{.hi}

$$
\hat{\beta}_1 = \bar{Y} - \hat{\beta}_2 \bar{X}
$$

:::

::: {.column width="60%"}
[Slope:]{.hp}

$$
\begin{aligned}
\hat{\beta}_2 &= \dfrac{\sum_{i=1}^n (Y_i - \bar{Y})(X_i - \bar{X})}{\sum_{i=1}^n  (X_i - \bar{X})^2}
\end{aligned}
$$
:::
::::

We used these formulas to obtain estimates of the parameters $\beta_1$ and $\beta_2$ in a regression of $Y_i$ on $X_i$.

---

## Last Time

With the [OLS]{.hi} estimates, we constructed a regression line: 

$$
 \hat{Y_i} = \hat{\beta}_1 + \hat{\beta}_2X_i.
$$

- $\hat{Y_i}$ are predicted or [fitted]{.note} values of $Y_i$. 
- Think of $\hat{Y_i}$ as an estimated average value of $Y_i$ given a particular $X_i$. 

. . .

[OLS]{.hi} still produces prediction errors: $\hat{u}_i = Y_i - \hat{Y_i}$.

- Put differently, there is a part of $Y_i$ we can explain and a part we cannot: $Y_i = \hat{Y_i} + \hat{u}_i$.

---

## Review

What is the equation for the regression model estimated below? 

```{R}
#| echo: false
#| fig.height: 5.75
#| fig.align: center

df_earn %>% 
  ggplot() +
  xlim(0, 20) +
  geom_point(aes(x = x, y = y), color = hi) +
  geom_abline(intercept = b0_earn, slope = b1_earn, color = hp, size = 2) +
  mytheme + xlab("Years of Education") + ylab("Hourly Earnings")
```

<br>

---

## Review {data-visibility="uncounted"}

The estimated [intercept]{.hi} is `r round(lm_earn$coefficients[1], 2)`. What does this tell us? 

```{R}
#| echo: false
#| fig.height: 5.75
#| fig.align: center

df_earn %>% 
  ggplot() +
  xlim(0, 20) +
  geom_point(aes(x = x, y = y), color = hi) +
  geom_abline(intercept = b0_earn, slope = b1_earn, color = hp, size = 2) +
  mytheme + xlab("Years of Education") + ylab("Hourly Earnings")
```

[With [zero]{.note} years of education, estimate hourly earnings would be --$10.44]{.fragment}

---

## Review {data-visibility="uncounted"}

The estimated [slope]{.hp} is `r round(lm_earn$coefficients[2], 2)`. How do we interpret it?

```{R}
#| echo: false
#| fig.height: 5.75
#| fig.align: center

df_earn %>% 
  ggplot() +
  xlim(0, 20) +
  geom_point(aes(x = x, y = y), color = hi) +
  geom_abline(intercept = b0_earn, slope = b1_earn, color = hp, size = 2) +
  mytheme + xlab("Years of Education") + ylab("Hourly Earnings")
```

[For each additional year of schooling, hourly earnings increase by $2.32]{.fragment}